{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDlx3KtIvxet",
    "outputId": "43fc16b6-4d53-4b28-bba2-88e2c7d3c928"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/laks007/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2024-03-25 21:16:02.543857: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F4s38p5Kysql"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# modeling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkqqplurv9CI",
    "outputId": "acde8680-178e-4586-d816-df15b6d07445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-25 23:43:01--  https://dagshub.com/Omdena/HyderabadIndiaChapter_MentalHealthWellbeingFomoSocialMedia/raw/9624be1317f2735a0f84db62a3094bed0b087cf4/data/preprocessed_data/combined_data_sentiment_bert.csv\n",
      "Resolving dagshub.com (dagshub.com)... 35.186.200.224\n",
      "Connecting to dagshub.com (dagshub.com)|35.186.200.224|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘combined_data_sentiment_bert.csv.3’\n",
      "\n",
      "combined_data_senti     [     <=>            ]  20.49M  21.4MB/s    in 1.0s    \n",
      "\n",
      "2024-03-25 23:43:03 (21.4 MB/s) - ‘combined_data_sentiment_bert.csv.3’ saved [21487641]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://dagshub.com/Omdena/HyderabadIndiaChapter_MentalHealthWellbeingFomoSocialMedia/raw/9624be1317f2735a0f84db62a3094bed0b087cf4/data/preprocessed_data/combined_data_sentiment_bert.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "data_path = os.path.join(os.path.dirname(os.path.dirname(curr_dir)), 'data','preprocessed_data','combined_data_sentiment_bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBGd4m0IwAfl",
    "outputId": "2e667b73-ed6d-4231-e4db-0368003e72c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line (header) looks like this:\n",
      "\n",
      "Text,Negative Score,Neutral Score,Positive Score,Predicted Sentiment\n",
      "\n",
      "Each data point looks like this:\n",
      "\n",
      "msm left pushing u mental health crisis coronavirus people sick,0.9619251,0.03580601,0.0022688184,Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(data_path, 'r') as csvfile:\n",
    "    print(f\"First line (header) looks like this:\\n\\n{csvfile.readline()}\")\n",
    "    print(f\"Each data point looks like this:\\n\\n{csvfile.readline()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Z-TkaUd1wBxF",
    "outputId": "e55d4063-7edf-49c3-fd5d-136e034c84cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Neutral Score</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Predicted Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msm left pushing u mental health crisis corona...</td>\n",
       "      <td>0.9619251</td>\n",
       "      <td>0.03580601</td>\n",
       "      <td>0.0022688184</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breaking democrat launched another investigati...</td>\n",
       "      <td>0.34864902</td>\n",
       "      <td>0.6255751</td>\n",
       "      <td>0.025775908</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trying get pro statehood people go vote thats ...</td>\n",
       "      <td>0.7294451</td>\n",
       "      <td>0.24873672</td>\n",
       "      <td>0.021818098</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really sad even watch flunky cry whipped mind ...</td>\n",
       "      <td>0.9579343</td>\n",
       "      <td>0.039163336</td>\n",
       "      <td>0.002902385</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lynn shelton one wonderful advisor sundance la...</td>\n",
       "      <td>0.29626048</td>\n",
       "      <td>0.495577</td>\n",
       "      <td>0.20816256</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Negative Score  \\\n",
       "0  msm left pushing u mental health crisis corona...      0.9619251   \n",
       "1  breaking democrat launched another investigati...     0.34864902   \n",
       "2  trying get pro statehood people go vote thats ...      0.7294451   \n",
       "3  really sad even watch flunky cry whipped mind ...      0.9579343   \n",
       "4  lynn shelton one wonderful advisor sundance la...     0.29626048   \n",
       "\n",
       "  Neutral Score Positive Score Predicted Sentiment  \n",
       "0    0.03580601   0.0022688184            Negative  \n",
       "1     0.6255751    0.025775908             Neutral  \n",
       "2    0.24873672    0.021818098            Negative  \n",
       "3   0.039163336    0.002902385            Negative  \n",
       "4      0.495577     0.20816256             Neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaIzmuPmwMud",
    "outputId": "aa17823a-6569-4fe4-da14-d7f390ab5a12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative               120756\n",
       "Neutral                 83146\n",
       "Positive                21098\n",
       "Predicted Sentiment        44\n",
       "Name: Predicted Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Predicted Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Predicted Sentiment':'Sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows which has sentiment as predicted sentiment value other than neutral, positive, negetive\n",
    "df = df[df['Sentiment']!='Predicted Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Neutral Score</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msm left pushing u mental health crisis corona...</td>\n",
       "      <td>0.9619251</td>\n",
       "      <td>0.03580601</td>\n",
       "      <td>0.0022688184</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breaking democrat launched another investigati...</td>\n",
       "      <td>0.34864902</td>\n",
       "      <td>0.6255751</td>\n",
       "      <td>0.025775908</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trying get pro statehood people go vote thats ...</td>\n",
       "      <td>0.7294451</td>\n",
       "      <td>0.24873672</td>\n",
       "      <td>0.021818098</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really sad even watch flunky cry whipped mind ...</td>\n",
       "      <td>0.9579343</td>\n",
       "      <td>0.039163336</td>\n",
       "      <td>0.002902385</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lynn shelton one wonderful advisor sundance la...</td>\n",
       "      <td>0.29626048</td>\n",
       "      <td>0.495577</td>\n",
       "      <td>0.20816256</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Negative Score  \\\n",
       "0  msm left pushing u mental health crisis corona...      0.9619251   \n",
       "1  breaking democrat launched another investigati...     0.34864902   \n",
       "2  trying get pro statehood people go vote thats ...      0.7294451   \n",
       "3  really sad even watch flunky cry whipped mind ...      0.9579343   \n",
       "4  lynn shelton one wonderful advisor sundance la...     0.29626048   \n",
       "\n",
       "  Neutral Score Positive Score Sentiment  \n",
       "0    0.03580601   0.0022688184  Negative  \n",
       "1     0.6255751    0.025775908   Neutral  \n",
       "2    0.24873672    0.021818098  Negative  \n",
       "3   0.039163336    0.002902385  Negative  \n",
       "4      0.495577     0.20816256   Neutral  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "f2iOOCYhwRpz",
    "outputId": "9dd81ed0-e84c-4376-af23-71f0f11f3b95"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_percentages = df['Sentiment'].value_counts(normalize=True) * 100\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(class_percentages, labels=class_percentages.index, autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#b9f2f0', '#8de5a1'])\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    120756\n",
       "Neutral      83146\n",
       "Positive     21098\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfaG1i94wVql",
    "outputId": "26873f49-c6c9-426c-aba8-6faa38207b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 225000 entries, 0 to 225043\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   Text            225000 non-null  object\n",
      " 1   Negative Score  225000 non-null  object\n",
      " 2   Neutral Score   225000 non-null  object\n",
      " 3   Positive Score  225000 non-null  object\n",
      " 4   Sentiment       225000 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-uf3Dw6jwc9Y"
   },
   "outputs": [],
   "source": [
    "# encode the label\n",
    "df.loc[df['Sentiment'] == 'Negative', 'Label'] = 0\n",
    "df.loc[df['Sentiment'] == 'Neutral', 'Label'] = 1\n",
    "df.loc[df['Sentiment'] == 'Positive', 'Label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Neutral Score</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>msm left pushing u mental health crisis corona...</td>\n",
       "      <td>0.9619251</td>\n",
       "      <td>0.03580601</td>\n",
       "      <td>0.0022688184</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breaking democrat launched another investigati...</td>\n",
       "      <td>0.34864902</td>\n",
       "      <td>0.6255751</td>\n",
       "      <td>0.025775908</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trying get pro statehood people go vote thats ...</td>\n",
       "      <td>0.7294451</td>\n",
       "      <td>0.24873672</td>\n",
       "      <td>0.021818098</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really sad even watch flunky cry whipped mind ...</td>\n",
       "      <td>0.9579343</td>\n",
       "      <td>0.039163336</td>\n",
       "      <td>0.002902385</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lynn shelton one wonderful advisor sundance la...</td>\n",
       "      <td>0.29626048</td>\n",
       "      <td>0.495577</td>\n",
       "      <td>0.20816256</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Negative Score  \\\n",
       "0  msm left pushing u mental health crisis corona...      0.9619251   \n",
       "1  breaking democrat launched another investigati...     0.34864902   \n",
       "2  trying get pro statehood people go vote thats ...      0.7294451   \n",
       "3  really sad even watch flunky cry whipped mind ...      0.9579343   \n",
       "4  lynn shelton one wonderful advisor sundance la...     0.29626048   \n",
       "\n",
       "  Neutral Score Positive Score Sentiment  Label  \n",
       "0    0.03580601   0.0022688184  Negative    0.0  \n",
       "1     0.6255751    0.025775908   Neutral    1.0  \n",
       "2    0.24873672    0.021818098  Negative    0.0  \n",
       "3   0.039163336    0.002902385  Negative    0.0  \n",
       "4      0.495577     0.20816256   Neutral    1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LaNJgIOvwi9F",
    "outputId": "97c4de5f-c631-41ab-fb77-611468d7d87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 157500\n",
      "Length of validation set: 33750\n",
      "Length of test set: 33750\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into 3 sets: training, validation, testing with split ratio of 70%:15%:15%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove NaN values from 'df'\n",
    "df = df.dropna()\n",
    "\n",
    "# Split data to train, validation, test set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df['Text'], df['Label'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Further split the remaining data into validation and test set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Show how many data in each set\n",
    "print(\"Length of train set:\", len(X_train))\n",
    "print(\"Length of validation set:\", len(X_val))\n",
    "print(\"Length of test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmmV5oy1wmFd",
    "outputId": "1c41bd6a-1df0-4500-f5bb-1e44401fffc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168560    [moramo nastavimo, nastavimo radom, radom bolj...\n",
       "3873      [still sad, sad tbh, tbh remember, remember wa...\n",
       "224694    [learned certain, certain mental, mental healt...\n",
       "89471     [sad idec, idec show, show tube, tube anything...\n",
       "161260    [potential downside, downside enormous, enormo...\n",
       "                                ...                        \n",
       "119902    [sheriff call, call amp, amp say, say guy, guy...\n",
       "103714    [angry mob, mob worked, worked frenzy, frenzy ...\n",
       "131958    [yup allegation, allegation misconduct, miscon...\n",
       "146896    [sad fred, fred last, last tweet, tweet losing...\n",
       "121982    [speak lupe, lupe release, release snyder, sny...\n",
       "Name: Text, Length: 157500, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n",
    "    if lower_case:\n",
    "        message = message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "    if gram > 1:\n",
    "        w = []\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            w += [' '.join(words[i:i + gram])]\n",
    "        return w\n",
    "    if stop_words:\n",
    "        sw = stopwords.words('english')\n",
    "        words = [word for word in words if word not in sw]\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "X_train_preprocessed = X_train.apply(process_message)\n",
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_preprocessed = X_val.apply(process_message)\n",
    "X_test_preprocessed = X_test.apply(process_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VFk0tsIyPoe",
    "outputId": "b0a36bae-ca6f-4f11-a024-463be8cd2a78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breaking democrat democrat launched launched another another investigation investigation donald donald time time legal legal firing firing partisan'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join words into sentence\n",
    "X_train_ready = X_train_preprocessed.str.join(' ')\n",
    "X_train_ready[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_ready = X_val_preprocessed.str.join(' ')\n",
    "X_test_ready = X_test_preprocessed.str.join(' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrhvH6APwq-_"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pd2PlqcGxD6G"
   },
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E97bPed2wsPF",
    "outputId": "eb28bdd7-bf38-402c-e6f8-d295fdf0279a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Train Accuracy Score : 80.66285714285715% \n",
      "Naive Bayes Validation Accuracy Score  : 77.73037037037037% \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.75      0.84     22951\n",
      "         1.0       0.63      0.82      0.72      9562\n",
      "         2.0       0.37      0.97      0.53      1237\n",
      "\n",
      "    accuracy                           0.78     33750\n",
      "   macro avg       0.65      0.85      0.70     33750\n",
      "weighted avg       0.84      0.78      0.79     33750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "\n",
    "nb.fit(X_train_ready, y_train)\n",
    "\n",
    "valid_predict_nb = nb.predict(X_val_ready)\n",
    "\n",
    "train_accuracy = nb.score(X_train_ready, y_train)*100\n",
    "valid_accuracy_nb = accuracy_score(valid_predict_nb, y_val)*100\n",
    "\n",
    "print(\"Naive Bayes Train Accuracy Score : {}% \".format(train_accuracy))\n",
    "print(\"Naive Bayes Validation Accuracy Score  : {}% \".format(valid_accuracy_nb))\n",
    "print()\n",
    "print(classification_report(valid_predict_nb, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = 'i am wonderful today'\n",
    "p_msg = process_message(message)\n",
    "pred_label = nb.predict(p_msg)\n",
    "pred_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuuMQlsWxByr"
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cf5AK8agxFgT"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define TF-IDF vectorizer and SVM classifier in a Pipeline\n",
    "svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, max_df=0.8, min_df=5)),\n",
    "    ('clf', SVC(kernel='rbf'))  # Use RBF kernel\n",
    "])\n",
    "\n",
    "# Fit the SVM model\n",
    "svm.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "valid_predict_svm = svm.predict(X_val_ready)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "train_accuracy_svm = svm.score(X_train_ready, y_train) * 100\n",
    "valid_accuracy_svm = accuracy_score(valid_predict_svm, y_val) * 100\n",
    "\n",
    "# Print accuracy scores\n",
    "print(\"SVM Train Accuracy Score : {}%\".format(train_accuracy_svm))\n",
    "print(\"SVM Validation Accuracy Score: {}%\".format(valid_accuracy_svm))\n",
    "print()\n",
    "print(classification_report(valid_predict_svm, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm8oX76BxxUn"
   },
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "B5wtrbFcxwzU",
    "outputId": "0cf3067a-72ab-45f5-d0c4-1690fccd98cc"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4a169c41da17>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrf_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Predict on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100)),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "rf_pipeline.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "valid_predict_rf = rf_pipeline.predict(X_val)\n",
    "\n",
    "# Calculate and print the accuracy and classification report\n",
    "print(\"Random Forest Validation Accuracy Score:\", accuracy_score(y_val, valid_predict_rf))\n",
    "print(classification_report(y_val, valid_predict_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAYQzFFwxyp0"
   },
   "source": [
    "### Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7oqcFBczxHo",
    "outputId": "8dd6c57a-3ff0-43d5-8825-2f330851e9d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4922/4922 [==============================] - 399s 80ms/step - loss: -6.0429 - accuracy: 0.7221\n",
      "Epoch 2/5\n",
      "2177/4922 [============>.................] - ETA: 3:39 - loss: -21.1714 - accuracy: 0.8070"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_pad, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Predict on the validation set\u001b[39;00m\n\u001b[1;32m     34\u001b[0m valid_predict_lstm \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_pad)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Tokenizing texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "# Padding sequences\n",
    "max_length = max([len(x) for x in X_train_seq])  # Get max sequence length\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_length),\n",
    "    LSTM(100),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_pad, y_train, epochs=5)\n",
    "\n",
    "# Predict on the validation set\n",
    "valid_predict_lstm = model.predict(X_val_pad)\n",
    "valid_predict_lstm = [1 if prob > 0.5 else 0 for prob in valid_predict_lstm]\n",
    "\n",
    "# Calculate and print the accuracy and classification report\n",
    "print(\"LSTM Validation Accuracy Score:\", accuracy_score(y_val, valid_predict_lstm))\n",
    "print(classification_report(y_val, valid_predict_lstm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S667D8in5z0w"
   },
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uMLdtoD569d",
    "outputId": "98aa1008-92ce-4d32-cc6c-62abf68f38d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDnfZCeZ52Ak",
    "outputId": "a48d9793-ad1d-465d-93ea-e5807704a78e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 9.577326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163087\n",
      "[LightGBM] [Info] Number of data points in the train set: 157500, number of used features: 5587\n",
      "[LightGBM] [Info] Start training from score -0.621042\n",
      "[LightGBM] [Info] Start training from score -0.995248\n",
      "[LightGBM] [Info] Start training from score -2.375326\n",
      "LightGBM Validation Accuracy Score: 85.18%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.91      0.89     18029\n",
      "         1.0       0.82      0.81      0.81     12474\n",
      "         2.0       0.86      0.70      0.77      3247\n",
      "\n",
      "    accuracy                           0.85     33750\n",
      "   macro avg       0.85      0.81      0.83     33750\n",
      "weighted avg       0.85      0.85      0.85     33750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Define the pipeline\n",
    "lgbm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', lgb.LGBMClassifier())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "lgbm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "valid_predict_lgbm = lgbm_pipeline.predict(X_val)\n",
    "\n",
    "# Calculate and print the accuracy and classification report\n",
    "valid_accuracy_lgbm = accuracy_score(y_val, valid_predict_lgbm) * 100\n",
    "print(f\"LightGBM Validation Accuracy Score: {valid_accuracy_lgbm:.2f}%\")\n",
    "print(classification_report(y_val, valid_predict_lgbm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBVPOP9m7UZN"
   },
   "source": [
    "### roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-tNt7eD7W2x",
    "outputId": "5677ff08-3e69-4cab-e5b6-d544cb55e156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p194Ho_Y8LPQ",
    "outputId": "e4b4497b-3af3-4d75-9daf-64fa9500fe3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_omLr6hR9S9B",
    "outputId": "da46ca19-ef8d-4242-d819-e71fde87c134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.39.1\n",
      "Accelerate version: 0.28.0\n",
      "Torch version: 2.2.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import accelerate\n",
    "import torch\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Accelerate version:\", accelerate.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrG_jkw88nEI"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate==0.21.0\n",
    "!pip install transformers==4.5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7xGatkY7bNK"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenizer, texts, labels=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokenized = self.tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        input_ids = tokenized['input_ids'][0]\n",
    "        attention_mask = tokenized['attention_mask'][0]\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": torch.tensor(label)}\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = CustomDataset(tokenizer, X_train_ready, y_train)\n",
    "val_dataset = CustomDataset(tokenizer, X_val, y_val)\n",
    "\n",
    "# Initialize the model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda p: {'accuracy': (p.predictions.argmax(-1) == p.label_ids).mean()}\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UDLSBvWxTiB"
   },
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/45/6d/8c1d2570a52db6263d855c3ee3daf8f4bdf4a365cd6610772d6fce5fd904/xgboost-2.0.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /Users/laks007/anaconda3/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/laks007/anaconda3/lib/python3.11/site-packages (from xgboost) (1.10.1)\n",
      "Using cached xgboost-2.0.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (2.2 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgewBKZpxW_i",
    "outputId": "2a104b2e-6834-46e6-8244-3abb4907c27b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Train Accuracy Score : 85.53% \n",
      "XGBoost Validation Accuracy Score : 84.42% \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88     18663\n",
      "           1       0.82      0.80      0.81     12707\n",
      "           2       0.65      0.89      0.75      2380\n",
      "\n",
      "    accuracy                           0.84     33750\n",
      "   macro avg       0.79      0.85      0.81     33750\n",
      "weighted avg       0.85      0.84      0.85     33750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the pipeline\n",
    "xgb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', XGBClassifier()),  # Using XGBoost classifier\n",
    "               ])\n",
    "\n",
    "# Train the model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "valid_predict_xgb = xgb.predict(X_val)\n",
    "\n",
    "# Calculate accuracies\n",
    "train_accuracy_xgb = xgb.score(X_train, y_train) * 100\n",
    "valid_accuracy_xgb = accuracy_score(valid_predict_xgb, y_val) * 100\n",
    "\n",
    "# Print accuracy scores\n",
    "print(\"XGBoost Train Accuracy Score : {:.2f}% \".format(train_accuracy_xgb))\n",
    "print(\"XGBoost Validation Accuracy Score : {:.2f}% \".format(valid_accuracy_xgb))\n",
    "print()\n",
    "print(classification_report(valid_predict_xgb, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "with open('sentiment_classifier.pkl', 'wb') as f:\n",
    "            pickle.dump(xgb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "with open('sentiment_classifier.pkl', 'rb') as file:\n",
    "    xgb_loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def process_message(message, lower_case=True, stem=True, stop_words=True):\n",
    "    if lower_case:\n",
    "        message = message.lower()\n",
    "    \n",
    "    words = word_tokenize(message)\n",
    "    \n",
    "    if stop_words:\n",
    "        sw = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in sw]\n",
    "    \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = 'i am feeling sad'\n",
    "processed_msg = process_message(msg)\n",
    "pred_label = xgb.predict([processed_msg])\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzsIIYjM6xUe"
   },
   "source": [
    "### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kk6yBW1m60sj"
   },
   "outputs": [],
   "source": [
    "pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MAR00yu6h5p"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Define a custom dataset class\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenizer, texts, labels=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokenized_input = self.tokenizer(self.texts[idx], padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        input_ids = tokenized_input['input_ids'][0]\n",
    "        attention_mask = tokenized_input['attention_mask'][0]\n",
    "        if self.labels is not None:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': label}\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = TextDataset(tokenizer, X_train_ready, y_train)\n",
    "val_dataset = TextDataset(tokenizer, X_val, y_val)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./roberta_results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGpgxYGWA6_w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
