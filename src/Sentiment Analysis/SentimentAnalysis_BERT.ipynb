{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8ILaJQkI9Fw",
        "outputId": "c39337f2-fe34-4433-db48-4cca43d0a98b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Stbvy0vtJB-c"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srCfEZXFJKHC",
        "outputId": "e9ede339-84b6-4c97-d1e3-6122994abc16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydnIJe6RJOm2",
        "outputId": "80c4e6ee-9a31-4956-a9d7-34ff5a63c11b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            Text\n",
            "0                 yeah sad liked\n",
            "1            sad hear rest peace\n",
            "2              sad one even care\n",
            "3                       perioddd\n",
            "4  someone hated twitter account\n"
          ]
        }
      ],
      "source": [
        "# input file path\n",
        "input_path = \"/content/drive/My Drive/Colab Notebooks/preprocessed_output.txt\"\n",
        "\n",
        "# Read the text from the file and remove newline characters\n",
        "with open(input_path, 'r') as file:\n",
        "    text = [line.rstrip() for line in file.readlines()]\n",
        "\n",
        "# Create a DataFrame with the text\n",
        "result_df = pd.DataFrame({'Text': text})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gO6NvMetlcA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Output directory in your Google Drive\n",
        "output_dir = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
        "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
        "\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "batch_size = 5000  # Batch size for processing\n",
        "num_rows = len(result_df)  # Total number of rows\n",
        "start_index = 0  # Start index for the first batch\n",
        "\n",
        "while start_index < num_rows:\n",
        "    end_index = min(start_index + batch_size, num_rows)  # Calculate the end index for the current batch\n",
        "\n",
        "    # Initialize lists to store sentiment predictions and scores for the current batch\n",
        "    batch_predicted_sentiments = []\n",
        "    batch_sentiment_scores = {'Negative': [], 'Neutral': [], 'Positive': []}\n",
        "\n",
        "    # Iterate over the current batch of rows\n",
        "    for index, row in result_df.iloc[start_index:end_index].iterrows():\n",
        "        preprocessed_tweet = row['Text']\n",
        "        encoded_tweet = tokenizer(preprocessed_tweet, return_tensors='pt')\n",
        "\n",
        "        output = model(**encoded_tweet)\n",
        "\n",
        "        predicted_sentiment = labels[torch.argmax(output.logits).item()]\n",
        "        batch_predicted_sentiments.append(predicted_sentiment)\n",
        "\n",
        "        scores = torch.nn.functional.softmax(output.logits, dim=1).detach().numpy()[0]\n",
        "        batch_sentiment_scores['Negative'].append(scores[0])\n",
        "        batch_sentiment_scores['Neutral'].append(scores[1])\n",
        "        batch_sentiment_scores['Positive'].append(scores[2])\n",
        "\n",
        "    # Create DataFrame for the current batch of rows\n",
        "    batch_df = result_df.iloc[start_index:end_index].copy()\n",
        "\n",
        "    # Drop 'Text' column if present\n",
        "    #if 'Text' in batch_df.columns:\n",
        "    #    batch_df.drop('Text', inplace=True, axis=1)\n",
        "\n",
        "    # Add sentiment scores and predicted sentiment to DataFrame\n",
        "    batch_df['Negative Score'] = batch_sentiment_scores['Negative']\n",
        "    batch_df['Neutral Score'] = batch_sentiment_scores['Neutral']\n",
        "    batch_df['Positive Score'] = batch_sentiment_scores['Positive']\n",
        "    batch_df['Predicted Sentiment'] = batch_predicted_sentiments\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    output_csv_path = os.path.join(output_dir, f\"predicted_sentiments_{start_index}_{end_index}.csv\")\n",
        "    batch_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"CSV file saved successfully: {output_csv_path}\")\n",
        "\n",
        "    start_index = end_index  # Update the start index for the next batch\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}